
# ğŸ“˜ README

## âœ… Setup + Run Instructions

### 1. Clone the Repository & Setup Environment
```bash
git clone https://github.com/your-username/docbot.git
cd docbot
python -m venv venv
venv\Scripts\activate     
pip install -r requirements.txt
```

### 2. Create `.env` File
Create a `.env` file in the root directory with your Groq API key:
```
GROQ_API_KEY=your_groq_api_key
```

### 3. Run the Flask App
```bash
python main.py
```

### 4. Run the Demo Notebook
Open `demo_script.ipynb` and execute:
- Folder uploaded_docs
- 3 question tests
- View chatbot answers with citations

---

## ğŸ§± Architecture Overview Diagram

```
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Documents   â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
       â”‚  Parser     â”‚  â† Extracts clean text
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
              â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
       â”‚ Embedder    â”‚  â† Embeds chunks via SentenceTransformers
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
              â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
       â”‚ Retriever   â”‚  â† Top-k semantic search
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
              â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
       â”‚ Generator   â”‚  â† LLM generates answer w/ citations
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  Description of How It Works

### ğŸ”¹ Embedding
- Documents are parsed and chunked.
- Embeddings are generated using `sentence-transformers`.

### ğŸ”¹ Retrieval
- User question is embedded.
- Cosine similarity is used to retrieve top-k most relevant chunks.

### ğŸ”¹ Generation
- Retrieved chunks and question are sent to a Groq-powered LLM (e.g., LLaMA 3).
- Answer is generated (â‰¤ 500 words) with inline citations:  
 


